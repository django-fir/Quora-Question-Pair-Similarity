{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9r763jIis6G4"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 : EDA: Advanced Feature Extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqQkR0V81Iw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiMCWQxW1JWq",
        "outputId": "cae273ac-76ee-4d8b-b23c-3f048151e8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrWQOMctJrCD",
        "outputId": "66995507-d3fa-4fad-9039-2ab46523deac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZzMgMwJHI6",
        "outputId": "19b33501-91b5-4401-ec17-19027f44faf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting distance\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=8009261a18c1559f8dc9687edddf163c4457f4b4a11b88816b6361224f1e8a00\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "Successfully built distance\n",
            "Installing collected packages: distance\n",
            "Successfully installed distance-0.1.3\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "omBYR9Pms6G6",
        "outputId": "7afb19c8-2abf-443f-ed8a-15cce06fd675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from fuzzywuzzy import fuzz\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from os import path\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "TWQAzMyWs6HU"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> 3.4 Preprocessing of Text </h2>"
      ]
    },
    {
      "metadata": {
        "id": "P2_6a1Ils6HV"
      },
      "cell_type": "markdown",
      "source": [
        "- Preprocessing:\n",
        "    - Removing html tags\n",
        "    - Removing Punctuations\n",
        "    - Performing stemming\n",
        "    - Removing Stopwords\n",
        "    - Expanding contractions etc."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y931kwKQTfgD",
        "outputId": "c6b52126-7f8d-46f1-951d-aa3ff3c8d1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "jgE3QuLws6HW"
      },
      "cell_type": "code",
      "source": [
        "# To get the results in 4 decemal points\n",
        "SAFE_DIV = 0.0001\n",
        "\n",
        "STOP_WORDS = stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
        "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "\n",
        "\n",
        "    porter = PorterStemmer()\n",
        "    pattern = re.compile('\\W')\n",
        "\n",
        "    if type(x) == type(''):\n",
        "        x = re.sub(pattern, ' ', x)\n",
        "\n",
        "\n",
        "    if type(x) == type(''):\n",
        "        x = porter.stem(x)\n",
        "        example1 = BeautifulSoup(x)\n",
        "        x = example1.get_text()\n",
        "\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZ4FNZZns6Hc"
      },
      "cell_type": "markdown",
      "source": [
        "- Function to Compute and get the features : With 2 parameters of Question 1 and Question 2"
      ]
    },
    {
      "metadata": {
        "id": "FkzcDTs5s6He"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> 3.5 Advanced Feature Extraction (NLP and Fuzzy Features) </h2>"
      ]
    },
    {
      "metadata": {
        "id": "GSJiSSUEs6He"
      },
      "cell_type": "markdown",
      "source": [
        "Definition:\n",
        "- __Token__: You get a token by splitting sentence a space\n",
        "- __Stop_Word__ : stop words as per NLTK.\n",
        "- __Word__ : A token that is not a stop_word\n",
        "\n",
        "\n",
        "Features:\n",
        "- __cwc_min__ :  Ratio of common_word_count to min lenghth of word count of Q1 and Q2 <br>cwc_min = common_word_count / (min(len(q1_words), len(q2_words))\n",
        "<br>\n",
        "<br>\n",
        "- __cwc_max__ :  Ratio of common_word_count to max lenghth of word count of Q1 and Q2 <br>cwc_max = common_word_count / (max(len(q1_words), len(q2_words))\n",
        "<br>\n",
        "<br>\n",
        "- __csc_min__ :  Ratio of common_stop_count to min lenghth of stop count of Q1 and Q2 <br> csc_min = common_stop_count / (min(len(q1_stops), len(q2_stops))\n",
        "<br>\n",
        "<br>\n",
        "- __csc_max__ :  Ratio of common_stop_count to max lenghth of stop count of Q1 and Q2<br>csc_max = common_stop_count / (max(len(q1_stops), len(q2_stops))\n",
        "<br>\n",
        "<br>\n",
        "- __ctc_min__ :  Ratio of common_token_count to min lenghth of token count of Q1 and Q2<br>ctc_min = common_token_count / (min(len(q1_tokens), len(q2_tokens))\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "- __ctc_max__ :  Ratio of common_token_count to max lenghth of token count of Q1 and Q2<br>ctc_max = common_token_count / (max(len(q1_tokens), len(q2_tokens))\n",
        "<br>\n",
        "<br>\n",
        "        \n",
        "- __last_word_eq__ :  Check if First word of both questions is equal or not<br>last_word_eq = int(q1_tokens[-1] == q2_tokens[-1])\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "- __first_word_eq__ :  Check if First word of both questions is equal or not<br>first_word_eq = int(q1_tokens[0] == q2_tokens[0])\n",
        "<br>\n",
        "<br>\n",
        "        \n",
        "- __abs_len_diff__ :  Abs. length difference<br>abs_len_diff = abs(len(q1_tokens) - len(q2_tokens))\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "- __mean_len__ :  Average Token Length of both Questions<br>mean_len = (len(q1_tokens) + len(q2_tokens))/2\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "- __fuzz_ratio__ :  https://github.com/seatgeek/fuzzywuzzy#usage\n",
        "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "- __fuzz_partial_ratio__ :  https://github.com/seatgeek/fuzzywuzzy#usage\n",
        "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "- __token_sort_ratio__ : https://github.com/seatgeek/fuzzywuzzy#usage\n",
        "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "- __token_set_ratio__ : https://github.com/seatgeek/fuzzywuzzy#usage\n",
        "http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- __longest_substr_ratio__ :  Ratio of length longest common substring to min lenghth of token count of Q1 and Q2<br>longest_substr_ratio = len(longest common substring) / (min(len(q1_tokens), len(q2_tokens))\n"
      ]
    },
    {
      "metadata": {
        "id": "h6eap_CRs6Hg"
      },
      "cell_type": "code",
      "source": [
        "def get_token_features(q1, q2):\n",
        "    token_features = [0.0]*10\n",
        "\n",
        "    # Converting the Sentence into Tokens:\n",
        "    q1_tokens = q1.split()\n",
        "    q2_tokens = q2.split()\n",
        "\n",
        "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
        "        return token_features\n",
        "    # Get the non-stopwords in Questions\n",
        "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
        "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
        "\n",
        "    #Get the stopwords in Questions\n",
        "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
        "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
        "\n",
        "    # Get the common non-stopwords from Question pair\n",
        "    common_word_count = len(q1_words.intersection(q2_words))\n",
        "\n",
        "    # Get the common stopwords from Question pair\n",
        "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
        "\n",
        "    # Get the common Tokens from Question pair\n",
        "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
        "\n",
        "\n",
        "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "\n",
        "    # Last word of both question is same or not\n",
        "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
        "\n",
        "    # First word of both question is same or not\n",
        "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
        "\n",
        "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
        "\n",
        "    #Average Token Length of both Questions\n",
        "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
        "    return token_features\n",
        "\n",
        "# get the Longest Common sub string\n",
        "\n",
        "def get_longest_substr_ratio(a, b):\n",
        "    strs = list(distance.lcsubstrings(a, b))\n",
        "    if len(strs) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
        "\n",
        "def extract_features(df):\n",
        "    # preprocessing each question\n",
        "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
        "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
        "\n",
        "    print(\"token features...\")\n",
        "\n",
        "    # Merging Features with dataset\n",
        "\n",
        "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "\n",
        "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
        "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
        "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
        "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
        "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
        "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
        "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
        "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
        "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
        "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
        "\n",
        "    #Computing Fuzzy Features and Merging with Dataset\n",
        "\n",
        "    #blog: http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
        "    # https://stackoverflow.com/questions/31806695/when-to-use-which-fuzz-function-to-compare-2-strings\n",
        "    # https://github.com/seatgeek/fuzzywuzzy\n",
        "    print(\"fuzzy features..\")\n",
        "\n",
        "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    # The token sort approach involves tokenizing the string in question, sorting the tokens alphabetically, and\n",
        "    # then joining them back into a string We then compare the transformed strings with a simple ratio().\n",
        "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drNGg9e-s6Hj",
        "outputId": "a94181f2-32b7-4649-c24a-d993b56bb2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "cell_type": "code",
      "source": [
        "if os.path.isfile('nlp_features_train.csv'):\n",
        "    df = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
        "    df.fillna('')\n",
        "else:\n",
        "    print(\"Extracting features for test:\")\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Project_gova/external_test.csv',encoding='latin-1')\n",
        "    df = extract_features(df)\n",
        "    df.to_csv(\"/content/drive/MyDrive/Project_gova/external_nlp_feature_test.csv\", index=False)\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for test:\n",
            "token features...\n",
            "fuzzy features..\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                       question1  \\\n",
              "0   1     1     2  tell me about sachin tendulkar   \n",
              "\n",
              "                                question2  freq_qid1  freq_qid2  q1len  q2len  \\\n",
              "0  explain briefly about sachin tendulkar          1          1     30     38   \n",
              "\n",
              "   q1_n_words  ...   ctc_max  last_word_eq  first_word_eq  abs_len_diff  \\\n",
              "0           5  ...  0.599988             1              0             0   \n",
              "\n",
              "   mean_len  token_set_ratio  token_sort_ratio  fuzz_ratio  \\\n",
              "0       5.0               85                71          76   \n",
              "\n",
              "   fuzz_partial_ratio  longest_substr_ratio  \n",
              "0                  86              0.741935  \n",
              "\n",
              "[1 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd732787-65b8-4f88-a543-83e3910e21bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>freq_qid1</th>\n",
              "      <th>freq_qid2</th>\n",
              "      <th>q1len</th>\n",
              "      <th>q2len</th>\n",
              "      <th>q1_n_words</th>\n",
              "      <th>...</th>\n",
              "      <th>ctc_max</th>\n",
              "      <th>last_word_eq</th>\n",
              "      <th>first_word_eq</th>\n",
              "      <th>abs_len_diff</th>\n",
              "      <th>mean_len</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>fuzz_ratio</th>\n",
              "      <th>fuzz_partial_ratio</th>\n",
              "      <th>longest_substr_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>tell me about sachin tendulkar</td>\n",
              "      <td>explain briefly about sachin tendulkar</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>85</td>\n",
              "      <td>71</td>\n",
              "      <td>76</td>\n",
              "      <td>86</td>\n",
              "      <td>0.741935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd732787-65b8-4f88-a543-83e3910e21bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd732787-65b8-4f88-a543-83e3910e21bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd732787-65b8-4f88-a543-83e3910e21bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRPgSJnom0Cp",
        "outputId": "532ed30c-41d1-47ed-971d-a1684b2dbbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'freq_qid1',\n",
              "       'freq_qid2', 'q1len', 'q2len', 'q1_n_words', 'q2_n_words',\n",
              "       'word_Common', 'word_Total', 'word_share', 'freq_q1+q2', 'freq_q1-q2',\n",
              "       'cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max',\n",
              "       'last_word_eq', 'first_word_eq', 'abs_len_diff', 'mean_len',\n",
              "       'token_set_ratio', 'token_sort_ratio', 'fuzz_ratio',\n",
              "       'fuzz_partial_ratio', 'longest_substr_ratio'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oz1Oin688c93"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}